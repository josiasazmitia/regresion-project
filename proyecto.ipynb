{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ciencia de Datos en Python - Proyecto #1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proyecto consiste en aplicar los conocimientos aprendidos en clase (y apoyandose de referencias adicionales utiles) para crear modelos predictivos de regresi´on lineal uni-variable sencillos de la forma:\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "y = β0 + β1 ∗ x\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "* y es la variable dependiente\n",
    "* x es la variable independiente\n",
    "* β0 es el intercepto de la recta\n",
    "* β1 es la pendiente de la recta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Usando sclicing con NumPy separar los datos en 2 datasets: entrenamiento(80 %) y validacion y pruebas(20 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Carga del archivo de entrenamiento\n",
    "data = np.load('./proyecto_training_data.npy')\n",
    "\n",
    "# buscamos obtner el 80% de la longitud del conjunto de datos\n",
    "train_size = int(len(data) * 0.8)\n",
    "\n",
    "# Utlizando slicing separamos el 80% de entrenamiento y 20% de validacion\n",
    "train_data = data[:train_size]\n",
    "validation_data = data[train_size:]\n",
    "\n",
    "#print(train_size)\n",
    "#print(validation_data)\n",
    "#validation_data\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {train_data.shape}\")\n",
    "print(f\"Conjunto de validación/pruebas: {validation_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Analisis exploratorio de datos: Para cada variable en el dataset calcular((usando numpy o pandas):\n",
    "* media\n",
    "* valor maximo\n",
    "* valor mınimo\n",
    "* rango(peak to peak, no el rango del tensor que por ser vector sabemos que es 1)\n",
    "* desviacion estandar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_statistics(data):\n",
    "    statistics = []\n",
    "    for i in range(data.shape[1]):\n",
    "        column = data[:, i][~np.isnan(data[:, i])]\n",
    "        mean = np.mean(column)  # Media\n",
    "        max_value = np.max(column)  # Valor máximo\n",
    "        min_value = np.min(column)  # Valor mínimo\n",
    "        range_value = np.ptp(column)  # Rango (peak to peak)\n",
    "        std_dev = np.std(column)  # Desviación estándar\n",
    "        \n",
    "        # Agregar las estadísticas calculadas a la lista\n",
    "        statistics.append((mean, max_value, min_value, range_value, std_dev))\n",
    "    return statistics\n",
    "\n",
    "# Calcular las estadísticas para los conjuntos de entrenamiento y de validación/pruebas\n",
    "train_statistics = calculate_statistics(train_data) # data entrenamiento 80%\n",
    "validation_statistics = calculate_statistics(validation_data) # data validacion 20%\n",
    "\n",
    "# Imprimir las estadísticas para el conjunto de entrenamiento\n",
    "print(\"Estadísticas del conjunto de entrenamiento:\")\n",
    "for i, stats in enumerate(train_statistics):\n",
    "    print(f\"Variable {i+1}: Media={stats[0]}, Máximo={stats[1]}, Mínimo={stats[2]}, Rango={stats[3]}, Desviación estándar={stats[4]}\")\n",
    "\n",
    "# Imprimir las estadísticas para el conjunto de validación/pruebas\n",
    "print(\"\\nEstadísticas del conjunto de validación/pruebas:\")\n",
    "for i, stats in enumerate(validation_statistics):\n",
    "    print(f\"Variable {i+1}: Media={stats[0]}, Máximo={stats[1]}, Mínimo={stats[2]}, Rango={stats[3]}, Desviación estándar={stats[4]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Para cada variable en el dataset usar seaborn(funcion distplot https://seaborn.pydata. org/generated/seaborn.distplot.html) para graficar un histograma de la variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "# ['SalePrice', 'OverallQual', '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'LotFrontage']\n",
    "variable_names = ['SalePrice', 'OverallQual', '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'LotFrontage']\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "# Crear un histograma para cada variable\n",
    "for i, var_name in enumerate(variable_names):\n",
    "    plt.figure(figsize=(10, 6))  # Tamaño de la figura\n",
    "    # Filtrar NaNs y utilizar histplot para la visualización\n",
    "    sns.displot(train_data[:, i][~np.isnan(train_data[:, i])], kde=False, color='blue')\n",
    "    #sns.histplot(train_data[:, i][~np.isnan(train_data[:, i])], bins=30, kde=False, color='blue')\n",
    "    plt.title(f'Histograma de {var_name}')\n",
    "    plt.xlabel(var_name)\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Para cada variable independiente x :\n",
    "* Calcular el coeficiente de correlacion entre x y y.\n",
    "* Graficar x vs y(scatterplot) usando matplotlib.\n",
    "* Colocar el coeficiente de correlaci´on y colocarlo como parte del tıtulo de la grafica.\n",
    "* Basado en la gr´afica y el coeficiente de correlacion de cada par x,y elegir las 2 variables con m´as potencial predictivo es decir las 2 variables que presentan mayor correlaci´on entre dicha variable y la variable dependiente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Variables independientes\n",
    "variable_names = ['OverallQual', '1stFlrSF', 'TotRmsAbvGrd', 'YearBuilt', 'LotFrontage']\n",
    "\n",
    "# SalePrice es la variable dependiente\n",
    "y = train_data[:, 0]\n",
    "\n",
    "for i, var_name in enumerate(variable_names, 1):\n",
    "    x = train_data[:, i]\n",
    "    valid_index = ~np.isnan(x)\n",
    "    correlation = np.corrcoef(y[valid_index], x[valid_index])[0, 1]\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x[valid_index], y[valid_index], color='blue')\n",
    "    plt.title(f\"{var_name} vs SalePrice (Correlación: {correlation:.2f})\")\n",
    "    plt.xlabel(var_name)\n",
    "    plt.ylabel('SalePrice')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Crear una funcion para entrenar un modelo de regresion lineal de una variable y = β0 +β1 ∗x.\n",
    "La funcion recibe como argumentos:\n",
    "* 6.1 Vector con la variable independiente x,\n",
    "* 6.2 Vector con la variable dependiente y,\n",
    "* 6.3 un entero epochs que indica por cuantas iteraciones entrenar el modelo.\n",
    "* 6.4 un entero imprimir error cada , que nos indica cada cuantas iteraciones queremos imprimir a traves de print: el numero de iteracion, el error del modelo en esa iteracion, si imprimir error cada = 10, se despliega en pantalla el error en las iteraciones:\n",
    "10,20,30,40,50.\n",
    "* 6.5 escalar α(learning rate): es usado como parte de la expresi´on matem´atica para actualizar en cada iteraci´on los par´ametros del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def entrenar_regresion_lineal(x, y, epochs, imprimir_error_cada, alpha):\n",
    "    beta_0 = 0  # Inicialización de parámetro\n",
    "    beta_1 = 0  # Inicialización de parámetro\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        y_pred = beta_0 + beta_1 * x  # Calcula la predicción\n",
    "        error = y - y_pred  # Calcula el error\n",
    "        cost = (error**2).mean()  # Calcula el costo\n",
    "\n",
    "        if epoch % imprimir_error_cada == 0:\n",
    "            print(f\"Iteración {epoch}, Error {cost}\")\n",
    "\n",
    "        # Actualiza los parámetros\n",
    "        beta_0 -= alpha * (-2 * error.mean())\n",
    "        beta_1 -= alpha * (-2 * (x * error).mean())\n",
    "\n",
    "    return beta_0, beta_1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
